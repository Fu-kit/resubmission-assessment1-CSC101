{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKfpsctQgP5whvjmrdmlUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fu-kit/resubmission-assessment1-CSC101/blob/main/resubmission_assessment1_csc101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW_9_tMSj7xE",
        "outputId": "37b4bb98-9dae-4aea-bb5e-7a38b942d944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please paste your text: Public perception about biology is crucial for developing scientific consensus.   Muscle cells bring parts of the body closer together.   The railway makes long-distance travel possible for everyone.   Our laboratory equipment is provided free of charge.   One student representative will be selected from each class.\n",
            "\n",
            "--- Analysis Results ---\n",
            "Total words: 44\n",
            "Average word length: 5.91\n",
            "Top 10 words:\n",
            "is - 2\n",
            "for - 2\n",
            "of - 2\n",
            "the - 2\n",
            "public - 1\n",
            "perception - 1\n",
            "about - 1\n",
            "biology - 1\n",
            "crucial - 1\n",
            "developing - 1\n"
          ]
        }
      ],
      "source": [
        "# Text Analysis Tool (TAT) - Weeks 1â€“4 Python only\n",
        "# Features: input text, tokenize, count words, top 10 words, averages\n",
        "\n",
        "# Step 1 - Input\n",
        "def get_user_text():\n",
        "    text = input(\"Please paste your text: \")\n",
        "    return text\n",
        "\n",
        "# Step 2 - Tokenize\n",
        "def tokenize_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation (keep only letters, digits, spaces)\n",
        "    clean_text = \"\"\n",
        "    for char in text:\n",
        "        if char.isalnum() or char.isspace():\n",
        "            clean_text += char\n",
        "    # Split into words\n",
        "    words = clean_text.split()\n",
        "    return words\n",
        "\n",
        "# Step 3 - Count\n",
        "def analyze_words(words):\n",
        "    # Total words\n",
        "    total_words = len(words)\n",
        "    # Total characters (no spaces)\n",
        "    total_chars = 0\n",
        "    for w in words:\n",
        "        total_chars += len(w)\n",
        "    # Average word length\n",
        "    if total_words > 0:\n",
        "        avg_word_length = total_chars / total_words\n",
        "    else:\n",
        "        avg_word_length = 0\n",
        "\n",
        "    # Count word frequencies (dictionary)\n",
        "    freq = {}\n",
        "    for w in words:\n",
        "        if w in freq:\n",
        "            freq[w] += 1\n",
        "        else:\n",
        "            freq[w] = 1\n",
        "\n",
        "    # Sort by frequency (high to low)\n",
        "    sorted_freq = sorted(freq.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Top 10 words\n",
        "    top_10 = sorted_freq[:10]\n",
        "\n",
        "    # Return results\n",
        "    return total_words, avg_word_length, top_10\n",
        "\n",
        "# Step 4 - Main program\n",
        "def main():\n",
        "    text = get_user_text()\n",
        "    words = tokenize_text(text)\n",
        "    total_words, avg_word_length, top_10 = analyze_words(words)\n",
        "\n",
        "    print(\"\\n--- Analysis Results ---\")\n",
        "    print(\"Total words:\", total_words)\n",
        "    print(\"Average word length:\", round(avg_word_length, 2))\n",
        "    print(\"Top 10 words:\")\n",
        "    for word, count in top_10:\n",
        "        print(word, \"-\", count)\n",
        "\n",
        "# Run the program\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1QpRwD7JnzW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}